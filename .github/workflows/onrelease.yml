name: Release pipeline

on:
  push:
    tags:
      - 'v*' # Push events to matching v*, i.e. v1.0, v20.15.10

jobs:
  release-pipeline:

    environment: "PROD"
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 4

    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_PROD_HOST }}
      DATABRICKS_TOKEN:  ${{ secrets.DATABRICKS_PROD_TOKEN }}

    steps:
      - uses: actions/checkout@v1

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install pip
        run: |
          python -m pip install --upgrade pip

      - name: Checkout repo
        uses: actions/checkout@v2

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run prod pipeline
        uses: databricks/run-notebook@v0
        with:
          local-notebook-path: notebooks/databricks_prod.py
          git-commit: ${{ github.event.pull_request.head.sha }}
          new-cluster-json: >
            {
              "num_workers": 1,
              "spark_version": "12.1.x-cpu-ml-scala2.12",
              "node_type_id": "i3.xlarge"
            }

      - name: Create Release
        id: create_release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
        with:
          tag_name: ${{ github.ref }}
          release_name: ${{ github.ref }}
          body: |
            Release for version ${{ github.ref }}.
          draft: false
          prerelease: false
